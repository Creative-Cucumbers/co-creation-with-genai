



[TOC]

# 1限目 AI活用と倫理

## 前回の振り返り (10分)

- AIの定義と歴史
- 生成AIと機会学習とディープラーニングの関係
- ワークショップで出た内容の共有

## 本講義の位置付け (5分)



| 回数     |     1      |       **2**        |                         3                         |                              4                              |                   5                    |                   6                    |     7      |             8-14             |
| -------- | :--------: | :----------------: | :-----------------------------------------------: | :---------------------------------------------------------: | :------------------------------------: | :------------------------------------: | :--------: | :--------------------------: |
| テーマ   |   AI基礎   | **AIの活用と倫理** | プロンプトエンジニアリング:インプット(要約・翻訳) | プロンプトエンジニアリング:アウトプット(ドキュメント生成等) | プロンプトエンジニアリング:アプリ生成① | プロンプトエンジニアリング:アプリ生成② |  総合演習  | フィジカルコンピューティング |
| 担当講師 | 小島、伊藤 |      **小島**      |                       伊藤                        |                            小島                             |                  伊藤                  |                  小島                  | 伊藤、小島 |           白石先生           |



## AIの活用見据えて (40分)

### 用語の整理 (10分)

#### **生成AI (generative AI)**

- 拡散モデル（diffusion model）や大規模言語モデル（large language model; LLM）を含む、画像や自然言語を生成するモデルを指す。
- 従来の識別モデル（あるいは識別関数）に対し、生成モデルという分類があり、生成側面に焦点を当てた呼び方。

#### **基盤モデル (foundation model)**

- 自然言語や画像など、事前に学習した汎用モデルを使い、様々なタスクに適用可能。
- 主にトランスフォーマー（2017年にGoogleの研究者によって提案された手法）が使用される。
- 大規模言語モデルを含み、自然言語や画像を跨ぐマルチモーダルな応用が多い。

#### **大規模言語モデル (large language model; LLM)**

- 言語データに特化し、深層学習（主にトランスフォーマー）による自己教師あり学習で訓練された大規模なモデル。
- OpenAIのGPT-4、GoogleのPaLM、MetaのLlamaなどが有名。
- ChatGPTは、GPT-4（またはGPT-3, GPT3.5）を対話用にチューニングしたもの。

#### **拡散モデル (Diffusion model)**

- 主に画像生成AIサービスで利用されるモデル。
- 元の画像データにノイズ（Gaussian Noise）を加えるForward processと、ノイズ状態から画像データを再構築するReverse Processの２つの段階を持つ。
- Stability AIのStable DiffusionやOpenAIのDALL・E2などが有名。

### トランスフォーマーと自己教師あり学習 (5分)

トランスフォーマーと自己教師あり学習は、現代の生成AI(大規模言語モデル)において非常に重要な役割を果たしています。これらの技術は、言語モデルの性能を飛躍的に向上させると同時に、新しいAIモデルの開発方法論に影響を与えています。

#### トランスフォーマー

トランスフォーマーは、2017年にGoogleの研究者によって発表されたアーキテクチャで、「Attention is All You Need」という論文で紹介されました。このモデルは従来のリカレントニューラルネットワーク（RNN）や畳み込みニューラルネットワーク（CNN）に代わるものとして設計されており、特に大量のデータを扱う際の効率性と効果性に優れています。

トランスフォーマーの主な特徴は、自己注意機構（Self-Attention）にあります。この機構により、入力される各単語は他の全単語との関連度を計算し、それに基づいて情報を集約することができます。これにより、文中の遠く離れた要素間の関連を直接モデル化することが可能となり、文脈理解が大幅に向上します。

#### 自己教師あり学習

自己教師あり学習は、ラベルのないデータからモデルが自身で学習を進める手法です。トランスフォーマーを用いた自然言語処理では、特に事前学習と呼ばれる段階でこの手法が用いられます。事前学習では、大量のテキストデータを利用して、文の次の単語を予測する、あるいは文中の欠落した単語を埋めるといったタスクを通じて、言語の一般的なパターンや文法を学習します。

この自己教師あり学習を経て、トランスフォーマーモデルはさまざまな下流タスク（翻訳、要約、質問応答など）に適応できるようになります。この段階をファインチューニングと呼び、特定のタスクにおいてモデルを最適化します。

### 大規模言語モデルとスケール則  (5分)

スケール則（scaling laws）は、モデルのパフォーマンスがモデルサイズ、データ量、計算量といったリソースのスケールに対してどのように変化するかを定量的に記述した法則です。大規模言語モデルの文脈で言えば、モデルのサイズ（パラメータ数）、訓練に使用されるデータの量、または訓練に投じられる計算資源を増やすことで、モデルの性能が向上する傾向が観察されています。



### 生成AIとトークン  (5分)

生成AI、特に言語モデルにおける「トークン」とは、テキストを処理しやすい単位に分割したものを指します。これらのトークンは、単一の文字、単語、あるいはその一部分（サブワード）であり得ます。具体的なトークン化の方法は使用されるモデルやその訓練目的に依存します。

モデル毎に生成AIを利用する際のインプット・アウトプット上限数が異なります。

| モデル  | インプット/アウトプット可能なトークン数 |
| ------- | --------------------------------------- |
| GPT-1   | 512                                     |
| GPT-2   | 1,024                                   |
| GPT-3.5 | ?? (演習)                               |
| PaLM    | 8,192                                   |
| GPT-4   | 25,000                                  |

### 演習: モデルのトークン上限を知ろう (10分)

ChatGPT3.5の最大トークン数を調べてみよう。  
また、自分のトークン数を調べる方法についても調査してみよう。
その後、最大トークン数より多い文字をいれるとどうなるかやってみよう。
以下をslackに投稿しましょう。

```
ChatGPT最大トークン数: 
トークン数の調査方法: 
最大トークン数以上いれるとどうなるか?:
```

###### 

slackに投稿できたら、[回答サンプル](./token_max_sample)を確認してみましょう。

### AIと職業に与える影響 (10分)

- 生成AI登場以前に予想されていた職業への影響
- 生成AI登場後に予想される職業への影響

## 休憩 (10分)

## AI倫理 (40分)

### AIリスクと対策

AI技術の急速な発展により、私たちの生活は多くの便利さを享受していますが、それに伴い多くのリスクも生じています。AIを利用する際に生じる潜在的なリスクとそれらに対する対策について解説します。

#### AIリスクストーリー: 新しいサービスの開発にAIを使用した場合　※まだ本事例は発生していない

#### タイトル: AIによるアイディアの流出

<img src="images/ai_risk_story.webp" alt="ai_risk_story" style="zoom:50%;" />

#### 登場人物

- **A子さん**：若くて野心的な起業家。新しいビジネスアイディアを具体化し、市場に導入しようとしている。

#### 背景

A子さんは最近、生成AIを活用して自分のビジネスアイディアを形にしていました。彼女は、AIを用いて、提案されたアイディアについてさまざまな角度から考察し、それをさらに発展させるための入力（プロンプト）を行っていました。このプロセスを通じて、A子さんは特に革新的なビジネスモデルを考え出し、その実現に向けて動き始めていました。

#### 事件の発展

ある日、A子さんはニュースで、ある大企業がまさに彼女が考えていたアイディアと非常に似た新サービスを発表したことを知ります。初めは偶然の一致かと思いましたが、そのアイディアは彼女がAIに入力したプロンプトと非常に細部まで一致していました。

#### 問題の解明

ショックを受けたA子さんは、使用していたAIサービスのプロバイダーに連絡を取り、何が起こったのかを尋ねました。調査の結果、AIサービスプロバイダーはユーザーがAIに入力したデータを、モデルの訓練データとして使用していることが判明しました。このプラクティスにより、他のユーザーも同様にAIサービスを利用していた大企業が、A子さんのアイディアに似たプロンプトを入力した結果、AIが生成したアイディアが彼女のものと酷似してしまったのです。

#### 教訓

この事件から、A子さんと他の起業家たちは、AIサービスを利用する際のリスクについて学びました。
特に、自分の創造的なアイディアや知的財産を保護するために、AIサービスの利用規約をよく理解し、どのようにデータが使用されるかを確認することの重要性が浮き彫りになりました。

### AIサービス構造で捉える

AIサービスを構造的に捉えることでリスクを整理しましょう。

<img src="images/ai_component.png" alt="ai_component" style="zoom:20%;" />

### AIリスク

1. 著作権や肖像権を侵害するリスク
2. 有害・危険な情報を流布するリスク
3. 個人情報を出力するリスク
4. 気密情報や個人情報が保存されるリスク
5. 事実と違う情報を出力するリスク (ハルシネーション)
6. 人であると誤解してしまうリスク
7. 責任の所在が不明確なリスク
8. 根拠にならない情報に基づいた判断リスク (バイアス)
9. AIの挙動を理解・説明できないリスク
10. 精度が徐々に悪化するリスク (データドリフト)
11. AI攻撃リスク (敵対的サンプル、回避攻撃、ノイズ耐性)
12. AI学習を祖先する攻撃を受けるリスク (ポイズニング)
13. プロンプトインジェクション 
14. モデルをコピーさせるリスク (抽出攻撃)



### 演習: ChatGPTに入力されるデータはどうなるか?

ChatGPTに入力したデータはどうなるでしょうか。
以下のフォーマットを参考にSlackに投稿してみましょう。

```
(デフォルト設定の場合)ChatGPTに入力したデータはどうなるか?
```

### AIと関連する人を整理して捉える

- AI利用者
- AI導入者 (サービスプロバイダ)
- AI開発者 (モデル開発者)

<img src="images/ai_risk_u.png" alt="ai_risk_u" style="zoom:20%;" />



<img src="images/ai_risk_p.png" alt="ai_risk_p" style="zoom:18%;" />



# 2限目 AIリスク対策演習

### 演習: 自分の好きなAIサービスに関する調査・考察 (30分)

- (前回ワークショップででたアイディアをベースに)
  自分が使いたいAIサービス(画像生成、音楽生成等々)を1つ決めましょう (10分)
- そのAIサービスにはどのようなリスクがあると思いますか? (5分)
  - 書き出してみましょう
- そのサービス規約にリスクと関連する記述があるか調査してみましょう。参考にしたサイトは参考文献に書いておきましょう。(10分)
- どのような対策をこうじることができるでしょうか、考えてみましょう。(10分)



```
例:
自分が使いたいAIサービス: ChatGPT
AIサービスリスクの考察:
- 事実と違う情報を出力するリスク
- 人であると誤解してしまうリスク
- 根拠にならない情報に基づいた判断リスク (バイアス)
リスクとサービス規約の調査:

事実と違う情報を出力するリスク: サービス規約に記述あり

参考:
Open AIサービス規約: https://openai.com/policies/terms-of-use)
```

## 休憩 (10分)



## 3. 参考情報

### 参考サービス

- ChatGPT4
- Gemini

### 参考文献

- [AIリスク教本](https://www.amazon.co.jp/AI%E3%83%AA%E3%82%B9%E3%82%AF%E6%95%99%E6%9C%AC-%E6%94%BB%E3%82%81%E3%81%AE%E3%83%87%E3%82%A3%E3%83%95%E3%82%A7%E3%83%B3%E3%82%B9%E3%81%A7%E5%8D%B1%E6%A9%9F%E5%9B%9E%E9%81%BF%EF%BC%86%E3%83%93%E3%82%B8%E3%83%8D%E3%82%B9%E5%8A%A0%E9%80%9F-%E6%97%A5%E6%9C%ACIBM-AI%E5%80%AB%E7%90%86%E3%83%81%E3%83%BC%E3%83%A0/dp/4296204084)
- [大規模言語モデルは新たな知能か](https://www.amazon.co.jp/%E5%A4%A7%E8%A6%8F%E6%A8%A1%E8%A8%80%E8%AA%9E%E3%83%A2%E3%83%87%E3%83%AB%E3%81%AF%E6%96%B0%E3%81%9F%E3%81%AA%E7%9F%A5%E8%83%BD%E3%81%8B%E2%80%95%E2%80%95ChatGPT%E3%81%8C%E5%A4%89%E3%81%88%E3%81%9F%E4%B8%96%E7%95%8C-%E5%B2%A9%E6%B3%A2%E7%A7%91%E5%AD%A6%E3%83%A9%E3%82%A4%E3%83%96%E3%83%A9%E3%83%AA%E3%83%BC-%E5%B2%A1%E9%87%8E%E5%8E%9F-%E5%A4%A7%E8%BC%94/dp/4000297198/ref=asc_df_4000297198/?tag=jpgo-22&linkCode=df0&hvadid=654954019163&hvpos=&hvnetw=g&hvrand=5543730617596746961&hvpone=&hvptwo=&hvqmt=&hvdev=c&hvdvcmdl=&hvlocint=&hvlocphy=1009461&hvtargid=pla-2198066508387&psc=1&mcid=69198d2972333467974f3f3cbf416e48&th=1&psc=1&gad_source=1)
- [教養としての生成AI](https://www.amazon.co.jp/-/en/%E6%B8%85%E6%B0%B4%E4%BA%AE-ebook/dp/B0CBLMWP91/ref=sr_1_32?crid=1212HENXZ5V&dib=eyJ2IjoiMSJ9.oqQPTYZpJ4c5utCMyR4AKqHFMYmNuEPzkEt_pnIzjN8sIueUPCHpB6qWJB0-8YTklyn_EPi0sVi6jX5MozNq8l753L4wYgmGzvC1JTRZE9Z6NlmodVSS-WCUpNAF3733-B3Av95pJmjURjuzyLLtYcc4uqSZDfBBLuu6Ko_DOwy3uH4rZrFt-j8RT1_dZd0MMwdXuDpV-AbxOOMiuK6vjn1cykS7q9iSaY4yyjL0oUeFPJ4dxaqFMRPG21ZNKoHJkRdq8C1m-6zEtjYN01Ql-h4R34SrHzoQA0F2o9taGR0.jdd0eL7BCXMTJ-cFPpyJcvGu5NW6wgbcTXBUmpw_qrE&dib_tag=se&keywords=%E7%94%9F%E6%88%90ai&qid=1712839430&sprefix=%E7%94%9F%E6%88%90ai+%2Caps%2C163&sr=8-32)

### 参考動画

- [「生成AI」(3) 松尾豊・東京大学大学院教授　2024.3.15](https://www.youtube.com/watch?v=U9vhGvFxKu0&t=8s)